Task Matrix:
System Overview: Arda Karaçal, Mustafa Umut Kaymaz, Baturalp İskenderoğlu, Önder Kemal Ceylan
Implementation Details: Arda Karaçal, Mustafa Umut Kaymaz, Baturalp İskenderoğlu, Önder Kemal Ceylan
Use Case Support in Design: Arda Karaçal, Mustafa Umut Kaymaz, Baturalp İskenderoğlu, Önder Kemal Ceylan
Design Decisions: Arda Karaçal, Mustafa Umut Kaymaz, Baturalp İskenderoğlu, Önder Kemal Ceylan
GitHub Commit Requirement: Arda Karaçal, Mustafa Umut Kaymaz, Baturalp İskenderoğlu, Önder Kemal Ceylan

	         | Brainstorming | Writing the document

Arda Karaçal            YES                YES

Önder Kemal Ceylan      YES                YES

Baturalp İskenderoğlu   YES                YES

Mustafa Umut Kaymaz     YES                YES

Table of Contents
	
	System Overview

		Brief Project Description
		Goals
		System Architecture
		Technology Stack
	
	Implementation Details

		Codebase Structure
		Key Implementations
		Component Interfaces
		Visual Interfaces
	
	Use Case Support in Design

		Use Case Selection
		Requirement Mapping
		Use Case Design
	
	Design Decisions

		Technology Comparisons
		Decision Justifications

1. System Overview

Brief Project Description:

	- Verilen restoranın menüsünü kullanıcıya sunmak ve seçili yemeğin en ucuz olduğu uygulamayı bulmak.

	Goals: 
		
	- Scrape the data from web and storing it in .csv files
	- Processing the data and find the cheapest food
	- Providing a basic GUI to user

System Architecture:

	Moduler Monolitic Architecture

Technology Stack:

	Text Editor: Vs Code

	Backend & Scripting: Python

	Web scraping libraries: Python request module and Beautifulsoup
	
	Databases: 

	Data processing: Pandas

	Frontend/GUI: Python tkinter module

	Version Control & Collaboration: GitHub 

2. Implementation Details

Codebase Structure:
	Folders: 
		/HesaplıYemek: Every module and .csv file in the program will be in HesaplıYemek folder
	Modules:
		Web_scraping.py: 
		indirimhesabı.py: 
		test.py: 
		GUI.py: 
		main.py:

Key Implementations:
	Web_scraping.py: The module that implements web scraping from different platforms, stores the data in .csv files
 
	indirimhesabı.py: The module that takes  .csv files as input and finding cheapest food, provide output for GUI.py

	test.py: The module that implements test methods and provides automated test for function by using pytest module

	GUI.py: The module that implements User Interface

	main.py The main file that runs the program 

Component Interfaces:
GUI Components

	run_gui(): Ana GUI uygulamasını başlatır ve bileşenleri ekler.

	fiyatlari_getir(): Kullanıcının girdiği adres ve restoran bilgisine göre menü fiyatlarını getirir.

	favori_sec(event): Seçilen favoriyi alıp konum ve restoran giriş alanlarını otomatik olarak doldurur.

Data Management

	secilen_csv_guncelle(): Sepete eklenen yemekleri güncelleyerek secilen.csv dosyasına kaydeder.

	guncelle_sepet(): Sepet içeriğini günceller ve GUI’ye yansıtır.

	fiyatlari_hesapla(): Sepetteki ürünlerin toplam fiyatlarını hesaplar.

Discount Calculation

	indirim_guncelle(): Kullanıcının seçtiği indirimleri uygular ve fiyat hesaplamasını günceller.
	hesapla_indirim(toplam_fiyat, joker, site):Verilen toplam fiyata göre indirim miktarını ve indirimli fiyatı hesaplar.
    

Favorites Handling

	favori_guncelle(): Favori restoranların favori.csv dosyasına kaydedilmesini sağlar.

	favorileri_yaz(): favori.csv dosyasındaki favorileri liste kutusuna yükler.

Web_Scraping
	fetch_data(): Webden aldığı verileri local'de .csv formatında depolar

Visual Interfaces:
	Screenshots are added.

3. Use Case Support in Design

Use Case Selection:

	Restoranlar sunulur
	Yemekler sepete eklenir
	Restoranlar favorilere kaydedilir.
	Yemeklerin indirimli fiyatları sunulur.

Requirement Mapping:
	
	Restoranların sunulması:
		The user must be able to search for restaurants
		The user must be able to enter a location
	Yemeklerin sepete eklenmesi:
		The user must be able to select a food
	Restoranların favorilere kaydedilmesi:
		The user must be able to pin restaurants
	Yemeklerin indirimli fiyatları sunulması:
		The user must be able to filter platforms
		The user must be able to select which coupons and/or codes to apply
		The user must be able to see the price after applying coupons and codes

Use Case Design:
	
	System Architecture:
	
	Data Flow Explanation:
		1) Web Scraping: Farklı restoran platformlarından Web_scraping.py modülü tarafından veri toplanır.
		2) Veri Depolama: Toplanan veriler, .csv uzantılı dosyalar halinde saklanır.
		3) Veri İşleme: data_processing.py dosyası, .csv dosyalarındaki veriyi girdi olarak alıp fiyat karşılaştırması yapar.
		4) Sonuçların Gösterimi: İşlenmiş veriler, GUI.py tarafından kullanıcıya sunulur.
	
	State Explanation:
	
	Bekleme Durumu:
		Sistem, kullanıcı girişini veya veri güncelleme isteğini bekler.
	
	Veri Toplama Durumu:

		Kullanıcının arama yapmasıyla, web scraping süreci başlar.
		Web Scraper modülü, ilgili platformlardan veri çeker.
	
	Veri İşleme Durumu:

		Toplanan CSV verileri, normalize edilip fiyat karşılaştırması yapılır.
		İşlem tamamlandığında, sonuçlar hazırlanır.
	
	Sonuç Görüntüleme Durumu:

		İşlenmiş veriler, GUI aracılığıyla ekrana aktarılır.
		Kullanıcı, sonuçları inceler ve gerekirse yeni sorgu başlatır.
	
	Test Durumu (Testing):

		Otomatik test senaryoları (test.py) çalıştırılarak modüllerin beklenen şekilde işlediği doğrulanır.
	


4. Design Decisions

Technology Comparisons:
	
1) Chosen:
	
Python’s requests module combined with BeautifulSoup for WebScraping.

   Alternative: 

Scrapy, which offers a more asynchronous framework for large-scale scraping.

   Why BeautifulSoup? :

For this project’s scope; finding restaurants, requesting menus from said restaurnats and BeautifulSoup are simpler to implement and maintain, while Scrapy might be more complex than needed for this project.


2) Chosen:

CSV files

   Alternative:

A relational database (e.g., SQLite)

   Why CSV's? :

CSV files integrate much easier with Pandas for data processing and are ideal for small to medium databases.A database, created by SQlite, would provide enhanced capabilities and data integrity but would add unnecessary complexity for a relatively small project


Decision Justifications:

-Database -> CSV:

Easy to generate, require no additional setup, and works well with Pandas for data processing. 

-Frameworks -> Python and It's Libraries (BeatifulSoup, Pandas, pytest, etc.):

Well-suited for web scraping, data processing, and prototyping. (primarily because of BeatifulSoup and Pandas)

-Architecture -> Modular Monolithic Architecture:

Allows for clear separation of concerns such as scraping, processing, GUI, etc. within a single unit, easier to develop and debug compared to more complex microservices architectures